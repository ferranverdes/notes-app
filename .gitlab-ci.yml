stages:
  - test
  - build
  - deploy
  - dast

include:
  - template: Jobs/Dependency-Scanning.gitlab-ci.yml # gemnasium-dependency_scanning
  - template: Jobs/Secret-Detection.gitlab-ci.yml # secret_detection
  - template: Jobs/SAST.gitlab-ci.yml # semgrep-sast
  - template: Jobs/SAST-IaC.gitlab-ci.yml # kics-iac-sast
  - template: Security/API-Security.gitlab-ci.yml # DAST API

gemnasium-dependency_scanning:
  variables:
    DS_MAX_DEPTH: -1 # scan all directories
    DS_EXCLUDED_PATHS: "**/node_modules/**,**/dist/**,**/build/**" # do not waste time on deps/build outputs
    DS_REMEDIATE: "false" # do not try to generate MRs with fixes

secret_detection:
  variables:
    SECRET_DETECTION_EXCLUDED_PATHS: "node_modules/**"
    SECRET_DETECTION_HISTORIC_SCAN: "false" # fast per-commit scans

semgrep-sast:
  variables:
    SAST_EXCLUDED_PATHS: "node_modules/**"

kics-iac-sast:
  variables:
    SEARCH_MAX_DEPTH: 5 # number of directory levels the analyzer descends into when searching for matching files to scan
    SAST_EXCLUDED_PATHS: "node_modules/**"

test:
  stage: test
  image: node:22-alpine
  variables:
    NODE_ENV: "test"
    DATABASE_URL: "file:./test.db"
  cache: # reuse deps between pipelines
    key:
      files: [app/package-lock.json] # refresh cache when lockfile changes
    paths:
      - app/node_modules/ # cache installed modules
      - app/.npm/ # cache npm package tarballs
    policy: pull-push # pull existing cache before job; update it after completion
  before_script:
    - cd app
  script:
    - npm ci --cache .npm --prefer-offline # install deps using cached packages when available
    - npm test -- --ci # npm stops parsing flags; runs Jest in CI mode

build:
  stage: build
  image: pulumi/pulumi-nodejs:3.205.0
  environment:
    name: $CI_COMMIT_BRANCH # defines the deployment environment (dev, stage, prod) so GitLab injects environment-scoped variables
  services:
    - docker:28.5.1-dind
  variables:
    DOCKER_TLS_CERTDIR: "" # disable TLS → simpler for local DinD
    DOCKER_HOST: "tcp://docker:2375"
  cache:
    key:
      files: [environments/package-lock.json]
    paths:
      - environments/node_modules/
      - environments/build/.npm/
    policy: pull-push
  before_script:
    - cd environments
    - echo "$GOOGLE_CREDENTIALS_B64" | base64 -d > ./credentials/service-account-key.json
    - export GOOGLE_APPLICATION_CREDENTIALS="$(pwd)/credentials/service-account-key.json"
    - cd build
  script:
    - npm ci --cache .npm --prefer-offline
    - pulumi stack select "$CI_COMMIT_BRANCH" || pulumi stack init "$CI_COMMIT_BRANCH" --non-interactive # temporary safeguard — remove 'stack init' once all env stacks are created
    - pulumi up --yes
    - echo "IMAGE_NAME=$(pulumi stack output imageName)" > build.env
    - echo "IMAGE_DIGEST=$(pulumi stack output repoDigest)" >> build.env
  artifacts: # define files to be passed between jobs (e.g. env vars, binaries, reports)
    reports:
      dotenv: environments/build/build.env
  only: # run this job only for these branches (dev, stage, prod)
    - dev
    - stage
    - prod

deploy:
  stage: deploy
  image: pulumi/pulumi-nodejs:3.205.0
  environment:
    name: $CI_COMMIT_BRANCH
  needs:
    - job: build # allows this job to start as soon as 'build' finishes and access its artifacts
  cache:
    key:
      files: [environments/package-lock.json]
    paths:
      - environments/node_modules/
      - environments/deploy/.npm/
    policy: pull-push
  before_script:
    - cd environments
    - echo "$GOOGLE_CREDENTIALS_B64" | base64 -d > ./credentials/service-account-key.json
    - export GOOGLE_APPLICATION_CREDENTIALS="$(pwd)/credentials/service-account-key.json"
    - cd deploy
  script:
    - npm ci --cache .npm --prefer-offline
    - pulumi stack select "$CI_COMMIT_BRANCH" || pulumi stack init "$CI_COMMIT_BRANCH" --non-interactive # temporary safeguard — remove 'stack init' once all env stacks are created
    - pulumi up --yes
    - echo "GCP_PROJECT=$(pulumi stack output project)" > deploy.env
    - echo "GCP_REGION=$(pulumi stack output region)" >> deploy.env
    - echo "SEED_JOB_NAME=$(pulumi stack output seedJobName)" >> deploy.env
    - echo "CLOUD_RUN_URL=$(pulumi stack output cloudRunUrl)" >> deploy.env
  artifacts:
    reports:
      dotenv: environments/deploy/deploy.env
  only:
    - dev
    - stage
    - prod

generate_openapi:
  stage: deploy
  image: node:22-alpine
  before_script:
    - cd app
    - npm ci --prefer-offline
  script:
    - npm run generate:openapi
  artifacts:
    paths:
      - app/docs/openapi.json
  only:
    - stage

seed_database: # triggers a Cloud Run job that inserts fake data into the database
  stage: deploy
  image: google/cloud-sdk:546.0.0-slim
  environment:
    name: $CI_COMMIT_BRANCH
  needs:
    - job: deploy
  before_script:
    - cd environments
    - echo "$GOOGLE_CREDENTIALS_B64" | base64 -d > ./credentials/service-account-key.json
    - gcloud auth activate-service-account --key-file=./credentials/service-account-key.json
    - gcloud config set project "$GCP_PROJECT"
  script:
    - gcloud run jobs execute "$SEED_JOB_NAME" --region="$GCP_REGION" --wait
  allow_failure: false # fail pipeline if seeding fails
  when: on_success # run automatically after successful deploy
  only:
    - dev
    - stage

dast_headers:
  stage: dast
  image: google/cloud-sdk:546.0.0-slim
  environment:
    name: $CI_COMMIT_BRANCH
  needs:
    - job: deploy
  rules:
    - if: '$CI_COMMIT_BRANCH == "stage"'
  before_script:
    - cd environments
    - echo "$GOOGLE_CREDENTIALS_DAST_B64" | base64 -d > ./credentials/dast-service-account-key.json
    - gcloud auth activate-service-account --key-file=./credentials/dast-service-account-key.json
  script:
    - export ACCESS_TOKEN="$(gcloud auth print-identity-token --audiences="$CLOUD_RUN_URL")"
    - 'echo "APISEC_REQUEST_HEADERS_BASE64=$(echo "Authorization: Bearer $ACCESS_TOKEN" | base64 -w0)" > headers.env'
  artifacts:
    reports:
      dotenv: environments/headers.env

api_security:
  stage: dast
  needs:
    - job: deploy # get CLOUD_RUN_URL from deploy.env
    - job: seed_database
    - job: dast_headers # get APISEC_REQUEST_HEADERS_BASE64 env var from headers.env
    - job: generate_openapi # get app/docs/openapi.json
  rules:
    - if: '$CI_COMMIT_BRANCH == "stage"'
  variables:
    APISEC_TARGET_URL: "$CLOUD_RUN_URL"
    APISEC_OPENAPI: "app/docs/openapi.json"
